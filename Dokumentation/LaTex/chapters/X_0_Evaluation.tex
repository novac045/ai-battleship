\section{Evaluation} \label{sec:Evaluation}

\subsection{Testkonzept}
\todoin{Bogi, Vic - lest euch das bitte durch und guckt ob wir das wirklich so verteidigen können.. thx}

	Ziel der durchgeführten Tests war es, mögliche Fehlerzustände im implementierten Programm aufzudecken und außerdem zu belegen, dass das System
	wie erwartet funktioniert. 
	
	% White Box
	% \todoin{Entwicklertest, Testbarkeit der Software (Treiber,...), Positiv- und Negativtests,}
	Da die Verwendung strukturorientierter Testverfahren die Entwicklung eines Testrahmens bedeuten und dies den Rahmen des Projektes sprengen würde,
	wurde von der Verwendung dieser Verfahren abgesehen.  
	Stattdessen wurde der Einsatz verschiedener Black-Box Methoden vorgesehen.
	
	% Black Box
	% \subsection{Funktionaler Test}
	Um zu überprüfen ob das entwickelte Spiel die gewünschten Funktionen bietet, wurden funktionale Tests durchgeführt. 
	Als Spezifikation hierfür wurden die in Abschnitt \ref{sec:Spielregeln} beschriebenen Eigenschaften des Spiels \textit{Schiffe-Versenken}
	verwendet. 
	
	\todoin{zustandsbasierter test - testet auch ungültige zustandsübergänge - möglcih???}
	
	% nicht funktional
	Außerdem wurden auch nicht funktionale Testverfahren verwendet. In diesem Kontext wurde auch ein Langzeittest durchgeführt, bei dem zwei
	Prolog-Clients 1000 Spiele gegeneinander spielen. Ziel dieses Tests war es diese hohe Anzahl von Spielen fehlerfrei zu beenden. 	
	
	\todoin{nicht funktional: portabilitätstest - wurde ja auf 2 plattformen entwickelt??!}
	\todoin{nicht funktional: Benutzbarkeit - wurde von beate verifiziert ;) }

\subsection{Testfälle}
	Zur Umsetzung des beschriebenen Testkonzepts (siehe Abschnitt \ref{sec:Evaluation}) wurden konkrete Testfälle konzeptioniert und
	durchgeführt. Im Folgenden werden die Testfälle, ihre Durchführung und das Testergebnis beschrieben. 

	\subsubsection{Testfall 1, Testfall 2} % (fold)
	\label{ssub:testfall_1_testfall_2}
		Der erste Testfall untersucht die korrekte Initialisierung des Prologclients. Insbesondere stellt die regelkonforme Platzieung der
		Schiffe einen wichtigen Bestandteil des Spiels dar. 

		Im gleichen Rahmen der Prüfung auf die korrekte Platzierung der Schiffe muss ebenfalls validiert werden, ob die geforderte Anzahl an Schiffen und die
		korrekten Schiffstypen auf dem Spielfeld zu finden sind. Dies stellt den zweiten Testfall dar.
	
		Zur Überprüfung der Korrektheit der Platzierung, der richtigen Gesamtanzahl der Schiffe, sowie die korrekte Anzahl der einzelnen Typen, wurden 
		die Startaufstellungen von 100 KI-gegen-KI spielen gespeichert und ausgewertet. Bei jedem KI-gegen-KI Spiel erzeugt der Prolog Client zwei 
		Aufstellungen (eine je KI-Spieler). Die so resultierenden 200 Aufstellungen wurden vom Entwicklerteam ausgewertet und auf Korrektheit in den 
		angegebenen Aspekten überprüft.
		
		\paragraph{Testergebnis} % (fold)
		\label{par:testergebnis}
			Das Überprüfen der 200 generierten Aufstellungen ergab folgendes Ergebnis:
			\begin{table}[H] % (fold)
				\centering
				\begin{tabular}{|p{.15\textwidth}|p{.14\textwidth}|p{.13\textwidth}|p{.15\textwidth}|p{.15\textwidth}|p{.11\textwidth}|} 
					\hline
					Geprüfte\newline Aufstellungen & Fehlerhafte Platzierung&Fehlerhafte Anzahl&Fehlerhafte Typen&Korrekte\newline Aufstellungen&Duplikate\\ 
					\hline\hline
					200 & 0 & 0 & 0 & 200 & 0\\
					\hline
				\end{tabular}
				\caption{Testresultat für Testfall 1 und Testfall2}
				\label{tbl:tf1tf2}
			\end{table}
			% table tbl:tf1tf2 (end)
		% paragraph testergebnis (end)
		Das Testergebnis zeigt, dass die Routine zum Platzieren der Schiffe wie erwartet arbeitet. Beim Testen wurde gleichzeitig auch überprüft, 
		wie oft Duplikate durch die Routine erzeugt werden (also identische Platzierungen).
		Das Auftreten keiner Duplikate lässt schlussfolgern, dass der Einsatz der Prolog-Systemprädikate \texttt{random/1} und \texttt{randseq/3} 
		den gewünschten Effekt liefern (siehe Abschnitt \ref{sec:initships}) und wie erwartet arbeiten.
		
		Die Liste der Ausgewerteten Textdaten befindet sich in \newline \texttt{Battleship\textbackslash MyField\_200Testdaten.txt}
	% subsubsection testfall_1_testfall_2 (end)
	\subsubsection{Testfall 3} % (fold)
	\label{ssub:testfall_3}
	
	Der dritte Testfall behandelt die Auswahl des nächsten anzugreifenden Spielfeldes. Im besonderen Fokus steht die Aufgabe der Verfolgung eines 
	getroffenen, aber noch nicht versenkten Schiffes.
	Hierfür wurde ein Spieler-gegen-KI spiel durchgeführt und die Ausgaben der KI in eine Datei umgeleitet. Das Spiel wurde künstlich in die Länge 
	gezogen bis die KI gewann, indem der Spieler gezielt auf unbelegte Spielfelder der KI geschossen hat.
	Nachdem die KI gewann, wurde die mitgeschriebene Datei, analysiert. Hierbei wurden die von der KI ausgewählten zu attakierenden Felder gegen die,
	durch die Strategie (siehe Abschnitt \ref{sec:strategy}) zu erwartenden überprüft. Diese Analyse ist in Tabelle \ref{tbl:testfall3} nachzuvollziehen.
	\input{includes/tbl_testfall3}
	
	\paragraph{Testergebnise} % (fold)
	\label{par:testergebnise}
	 \todoin {alles gut hier ...}
	% paragraph testergebnise (end)
	
	Der vierte Testfall untersucht die korrekte Behandlung eines versenkten Schiffes. Insbesondere soll geprüft werden, ob die Umgebung in einer 4er-Nachbarschaft
	mit Wasser aufgedeckt wird, da an diesen Stellen laut Regelbeschreibung keine Schiffe platziert werden dürfen und somit für die nachfolgenden Züge 
	uninteressant sind.
	\todoin{Beschreibung des Tests}
	
	Vorbedignung - KI Ausgabe auf der Konsole
	% subsubsection testfall_3 (end)
     \input{chapters/X_1_EvaluationJavaController}
	%- eigene Schiffe gültig platziert
	%- richtige anzahl und größe der schiffe
	%- gegnerische schiffe werden attackiert wenn ein treffer gelandet wurde
	%- gegnerisches schiff wird nach versenken mit wasser umschlossen
	%- 