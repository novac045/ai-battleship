\section{Evaluation} \label{sec:Evaluation}

\subsection{Testkonzept}
\todoin{Bogi, Vic - lest euch das bitte durch und guckt ob wir das wirklich so verteidigen können.. thx}

	Ziel der durchgeführten Tests war es, mögliche Fehlerzustände im implementierten Programm aufzudecken und außerdem zu belegen, dass das System
	wie erwartet funktioniert. 
	
	% White Box
	% \todoin{Entwicklertest, Testbarkeit der Software (Treiber,...), Positiv- und Negativtests,}
	Da die Verwendung strukturorientierter Testverfahren die Entwicklung eines Testrahmens bedeuten und dies den Rahmen des Projektes sprengen würde,
	wurde von der Verwendung dieser Verfahren abgesehen.  
	Stattdessen wurde der Einsatz verschiedener Black-Box Methoden vorgesehen.
	
	% Black Box
	% \subsection{Funktionaler Test}
	Um zu überprüfen ob das entwickelte Spiel die gewünschten Funktionen bietet, wurden funktionale Tests durchgeführt. 
	Als Spezifikation hierfür wurden die in Abschnitt \ref{sec:Spielregeln} beschriebenen Eigenschaften des Spiels \textit{Schiffe-Versenken}
	verwendet. 
	
	\todoin{zustandsbasierter test - testet auch ungültige zustandsübergänge - möglcih???}
	
	% nicht funktional
	Außerdem wurden auch nicht funktionale Testverfahren verwendet. In diesem Kontext wurde auch ein Langzeittest durchgeführt, bei dem zwei
	Prolog-Clients 1000 Spiele gegeneinander spielen. Ziel dieses Tests war es diese hohe Anzahl von Spielen fehlerfrei zu beenden. 	
	
	\todoin{nicht funktional: portabilitätstest - wurde ja auf 2 plattformen entwickelt??!}
	\todoin{nicht funktional: Benutzbarkeit - wurde von beate verifiziert ;) }

\subsection{Testfälle}
	Zur Umsetzung des beschriebenen Testkonzepts (siehe Abschnitt \ref{sec:Evaluation}) wurden konkrete Testfälle konzeptioniert und
	durchgeführt. Im Folgenden werden die Testfälle, ihre Durchführung und das Testergebnis beschrieben. 
	
	Für alle durchgeführten Testfälle des Prolog-Clients war es nötig, die Ausgabe auf eine Textdatei umzuleiten (siehe Abschnitt \ref{ssub:ausgabeverhalten}) 
	um die Auswertung von Spielverläufen zu erleichtern.

	\subsubsection{Testfall 1, Testfall 2} % (fold)
	\label{ssub:testfall_1_testfall_2}
		Der erste Testfall untersucht die korrekte Initialisierung des Prologclients. Insbesondere stellt die regelkonforme Platzieung der
		Schiffe einen wichtigen Bestandteil des Spiels dar. 

		Im gleichen Rahmen der Prüfung auf die korrekte Platzierung der Schiffe muss ebenfalls validiert werden, ob die geforderte Anzahl an Schiffen und die
		korrekten Schiffstypen auf dem Spielfeld zu finden sind. Dies stellt den zweiten Testfall dar.
	
		Zur Überprüfung der Korrektheit der Platzierung, der richtigen Gesamtanzahl der Schiffe, sowie die korrekte Anzahl der einzelnen Typen, wurden 
		die Startaufstellungen von 100 KI-gegen-KI spielen gespeichert und ausgewertet. Bei jedem KI-gegen-KI Spiel erzeugt der Prolog Client zwei 
		Aufstellungen (eine je KI-Spieler). Die so resultierenden 200 Aufstellungen wurden vom Entwicklerteam ausgewertet und auf Korrektheit in den 
		angegebenen Aspekten überprüft.
		
		\paragraph{Testergebnis} % (fold)
		\label{par:testergebnis}
			Das Überprüfen der 200 generierten Aufstellungen ergab folgendes Ergebnis:
			\begin{table}[H] % (fold)
				\centering
				\begin{tabular}{|p{.15\textwidth}|p{.14\textwidth}|p{.13\textwidth}|p{.15\textwidth}|p{.15\textwidth}|p{.11\textwidth}|} 
					\hline
					Geprüfte\newline Aufstellungen & Fehlerhafte Platzierung&Fehlerhafte Anzahl&Fehlerhafte Typen&Korrekte\newline Aufstellungen&Duplikate\\ 
					\hline\hline
					200 & 0 & 0 & 0 & 200 & 0\\
					\hline
				\end{tabular}
				\caption{Testresultat für Testfall 1 und Testfall2}
				\label{tbl:tf1tf2}
			\end{table}
			% table tbl:tf1tf2 (end)
		% paragraph testergebnis (end)
		Das Testergebnis zeigt, dass die Routine zum Platzieren der Schiffe wie erwartet arbeitet. Beim Testen wurde gleichzeitig auch überprüft, 
		wie oft Duplikate durch die Routine erzeugt werden (also identische Platzierungen).
		Das Auftreten keiner Duplikate lässt schlussfolgern, dass der Einsatz der Prolog-Systemprädikate \texttt{random/1} und \texttt{randseq/3} 
		den gewünschten Effekt liefern (siehe Abschnitt \ref{sec:initships}) und wie erwartet arbeiten.
		
		Die Liste der Ausgewerteten Textdaten befindet sich in \newline \texttt{Battleship\textbackslash MyField\_200Testdaten.txt}
	% subsubsection testfall_1_testfall_2 (end)
	\subsubsection{Testfall 3} % (fold)
	\label{ssub:testfall_3}
	
	Der dritte Testfall behandelt die Auswahl des nächsten anzugreifenden Spielfeldes. Im besonderen Fokus steht die Aufgabe der Verfolgung eines 
	getroffenen, aber noch nicht versenkten Schiffes.
	
	Hierfür wurde ein Spieler-gegen-KI spiel durchgeführt und die Ausgaben der KI in eine Datei umgeleitet. Das Spiel wurde künstlich in die Länge 
	gezogen bis die KI gewann, indem der Spieler gezielt auf unbelegte Spielfelder der KI geschossen hat.
	\todoin {Neu formulieren:}
	Nachdem die KI gewann, wurde die mitgeschriebene Datei, analysiert. Hierbei wurden die von der KI ausgewählten zu attakierenden Felder gegen die,
	durch die Strategie (siehe Abschnitt \ref{sec:strategy}) zu erwartenden überprüft. Diese Analyse ist in Tabelle \ref{tbl:testfall3} nachzuvollziehen.
	\input{includes/tbl_testfall3}
	
	\paragraph{Testergebnis} % (fold)
	\label{par:testergebnis}
	 Tabelle \ref{tbl:testfall3} stellt alle, von der KI gewählten Schüssen, den erwarteten gegenüber. Es ist zu sehen, dass die KI zu jeder Zeit 
	die durch die Spielstrategie vorgegebenen Koordinaten auswählt.
	
	Die Liste der Ausgewerteten Textdaten befindet sich in \newline \texttt{Battleship\textbackslash Output\_1.txt}
	% paragraph testergebnis (end)
	% subsubsection testfall_3 (end)
	\subsection{Testfall 4} % (fold)
	\label{sub:testfall_4}
		Der vierte Testfall untersucht die korrekte Behandlung eines versenkten Schiffes. Insbesondere soll geprüft werden, ob die Umgebung in 
		einer 4er-Nachbarschaft
		mit Wasser aufgedeckt wird, da an diesen Stellen laut Regelbeschreibung (siehe Abschnitt \ref{sec:Spielregeln}) keine Schiffe platziert werden dürfen 
		und somit für die nachfolgenden Züge uninteressant sind.
		
		Zur Testdurchführung wurde die für Testfall 3 (siehe Abschnitt \ref{ssub:testfall_3}) angefertigte Log-Datei in den Stellen ausgewertet, an denen ein 
		Schiff versenkt wurde. In Tabelle \ref{tbl:testfall3} sind diese Stellen hervorgehoben und so schnell in der Log-Datei wiederzufinden.
		An den betreffenden Stellen werden nun die Ausgaben des \texttt{enemyField} ausgewertet. Konkret wird das \texttt{enemyField} vor und 
		nach dem versenken eines Schiffes verglichen, um zu überprüfen ob die 4er-Nachbarschaft komplett mit Wasser aufgedeckt wird.
		\input{includes/tbl_testfall4}
		Zum besseren erkennen der Muster, wurden die Ausgaben des Ausgabemoduls nachträglich bearbeitet. Die Markierung für unbekannte Felder \texttt{U} wurde 
		durch \texttt{\_} ersetzt.
		\paragraph{Testergebnis} % (fold)
		\label{par:testergebnis}
			Wie in Tabelle \ref{tbl:testfall4} zu erkennen, wird nach jedem versenken eines Schiffes die komplette \emph{4er-Nachbarschaft} mit Wasser 
			aufgedeckt so wie es in im Abschnitt zur Spielstrategie (\ref{sec:strategy}) beschrieben ist.

			Die Liste der Ausgewerteten Textdaten befindet sich in \newline \texttt{Battleship\textbackslash Output\_1.txt}
		% paragraph testergebnis (end)
	% subsection testfall_4 (end)
    \input{chapters/X_1_EvaluationJavaController}